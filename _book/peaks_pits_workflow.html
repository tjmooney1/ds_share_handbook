<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Data Science at SHARE Creative - Peaks and Pits</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ai_landscape_workflow.html" rel="next">
<link href="./intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./peaks_pits_workflow.html">Peaks and Pits</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science at SHARE Creative</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface to handbook</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./peaks_pits_workflow.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Peaks and Pits</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai_landscape_workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI landscape</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-the-conceptproject-background" id="toc-what-is-the-conceptproject-background" class="nav-link active" data-scroll-target="#what-is-the-conceptproject-background">What is the concept/project background?</a>
  <ul class="collapse">
  <li><a href="#the-end-goal" id="toc-the-end-goal" class="nav-link" data-scroll-target="#the-end-goal">The end goal</a></li>
  <li><a href="#key-features-of-project" id="toc-key-features-of-project" class="nav-link" data-scroll-target="#key-features-of-project">Key features of project</a></li>
  </ul></li>
  <li><a href="#overview-of-approach" id="toc-overview-of-approach" class="nav-link" data-scroll-target="#overview-of-approach">Overview of approach</a>
  <ul class="collapse">
  <li><a href="#step-one" id="toc-step-one" class="nav-link" data-scroll-target="#step-one">Obtain posts for the project (Step 1)</a></li>
  <li><a href="#step-two" id="toc-step-two" class="nav-link" data-scroll-target="#step-two">Identify project-specific exemplar peaks and pits to fine-tune our ML model (Step 2)</a></li>
  <li><a href="#step-three" id="toc-step-three" class="nav-link" data-scroll-target="#step-three">Train our model using our labelled examples (Step 3)</a></li>
  <li><a href="#step-four" id="toc-step-four" class="nav-link" data-scroll-target="#step-four">Run inference over project data (Step 4)</a></li>
  <li><a href="#step-five" id="toc-step-five" class="nav-link" data-scroll-target="#step-five">The metal detector, GPT-3.5 (Step 5)</a></li>
  <li><a href="#step-six" id="toc-step-six" class="nav-link" data-scroll-target="#step-six">Topic modelling to make sense of our data (Step 6)</a></li>
  <li><a href="#the-idea" id="toc-the-idea" class="nav-link" data-scroll-target="#the-idea">The idea</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Peaks and Pits</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>‚ÄúPeak and Pits‚Äù is one of our fundamental project offerings and a workflow that is a solid representation of good data science work that we perform.</p>
<section id="what-is-the-conceptproject-background" class="level2">
<h2 class="anchored" data-anchor-id="what-is-the-conceptproject-background">What is the concept/project background?</h2>
<p>Strong memories associated to brands or products go deeper than simple positive or negative sentiment. In their book ‚ÄúThe Power of Moments‚Äù, two psychologists (<a href="https://heathbrothers.com/about/">Chip and Dan Heath</a>) define these core memories as Peak and Pits, impactful experiences in our lives.</p>
<p>Broadly, peak moments are experiences that stand our memorable in our lives in a positive sense, whereas pit moments are impactful negative experiences.</p>
<p>Microsoft tasked us with finding a way to identify these moments in social data- going beyond ‚Äòsimple‚Äô positive and negative sentiment which does not tell the full story of consumer/user experience. The end goal is that by providing Microsoft with these peak and pit moments in the customer experience, they can design peak moments in addition to simply removing pit moments.</p>
<section id="the-end-goal" class="level3">
<h3 class="anchored" data-anchor-id="the-end-goal">The end goal</h3>
<p>With these projects the core final ‚Äòproduct‚Äô is a collection of different peaks and pits, with suitable representative verbatims and an explanation to understand the high-level intricacies of these different emotional moments.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/peaks_list.png" class="img-fluid figure-img"></p>
<figcaption>Screenshot from a Peaks and Pits project showcasing the identified Peak moments for a product at a high level</figcaption>
</figure>
</div>
</section>
<section id="key-features-of-project" class="level3">
<h3 class="anchored" data-anchor-id="key-features-of-project">Key features of project</h3>
<ul>
<li>There is no out-of-the-box ML model available whose purpose is to classify social media posts as either peaks or pits (i.e.&nbsp;we cannot use a ready-made solution, we must design our own bespoke solution).</li>
<li>There is limited data available
<ul>
<li>Unlike the case of spam/ham or sentiment classification, there is not a bank of pre-labelled data available for us to leverage for ‚Äòtraditional ML‚Äô.</li>
</ul></li>
<li>Despite these issues, the research problem itself is well defined (<strong>what</strong> are the core peak and pit moments for a brand/product), and because there are only three classes (peak, pit, or neither) which are based on extensive research, the classes themselves are well described (even if it is case of ‚Äúyou know a peak moment when you see it‚Äù).</li>
</ul>
</section>
</section>
<section id="overview-of-approach" class="level2">
<h2 class="anchored" data-anchor-id="overview-of-approach">Overview of approach</h2>
<p>Peaks and pits have gone through many iterations throughout the past year and a half. Currently, the general workflow is to use utilise a model framework known as <a href="https://huggingface.co/docs/setfit/conceptual_guides/setfit">SetFit</a> to efficiently train a text classification model with limited training data. This fine-tuned model is then able to run inference over large datasets to label posts as either peaks, pits, or neither. We then utilise the LLM capabilities to refine these peak and pit moments into a collection of posts we are extremely confident are peaks and/or pits. We then employ topic modelling to identify groups of similar peaks and pits, to help us organise and discover hidden topics or themes within this collection of core moments.</p>
<p>This whole process can be split into seven distinct steps:</p>
<ol type="1">
<li><a href="#step-one">Extract brand/product mentions from Sprinklr (the start of any project)</a></li>
<li><a href="#step-two">Obtain project-specific exemplar posts to help fine-tune a text classification model</a></li>
<li><a href="#step-three">Perform model fine-tuning through contrastive learning</a></li>
<li><a href="#step-four">Run inference over all of the project specific data</a></li>
<li><a href="#step-five">Use GPT-3.5 for an extra layer of classification on identified peaks and pits</a></li>
<li><a href="#step-six">Turn moments into something interpretable using topic modelling</a></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/ar_workflow.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Schematic workflow from Project 706 - Peaks and Pits in M365 Apps</figcaption>
</figure>
</div>
<section id="step-one" class="level3">
<h3 class="anchored" data-anchor-id="step-one">Obtain posts for the project (Step 1)</h3>
<p>This step relies on the analysts to export relevant mentions from Sprinklr (one of the social listening tools that analysts utilise to obtain social data), and therefore is not detailed much here. What is required is one dataset for each of the brands/products, so they can be analysed separately.</p>
</section>
<section id="step-two" class="level3">
<h3 class="anchored" data-anchor-id="step-two">Identify project-specific exemplar peaks and pits to fine-tune our ML model (Step 2)</h3>
<p>This step is synonymous with data labelling required for any machine learning project where annotated data is not already available.</p>
<p>There is no perfect number of labelled examples to find per class (i.e.&nbsp;peak, pit, or neither). Whilst in general more exemplars (and hence more training data) is beneficial, having fewer but high quality labelled posts is far superior than more posts of poorer quality. This is extremely important due to the contrastive nature of SetFit where it‚Äôs superpower is making the most of few, extremely good, labelled data.</p>
<p>By the end of this step we need to have a list of examples posts we are confident represent what a peak or pit moment looks like for each particular product we are researching, including posts that are ‚Äúneither‚Äù.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why do we do this for each project? After so many projects now don‚Äôt we already have a good idea of what a peak and pit moment is for model training?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Each peak and pit project we work on has the potential to introduce ‚Äòdomain‚Äô specific language, which a machine learning classifier (model) may not have seen before. By manually identifying exemplar peaks and pits that are project-specific, this gives our model the best chance to identify emotional moments appropriate to the project/data at hand.</p>
<p>The obvious case for this is with gaming specific language, where terms that don‚Äôt necessarily relate to an ‚Äòobvious‚Äô peak or pit moment could refer to one the gaming conversation, for example the terms/phrases ‚ÄúGG‚Äù, ‚Äúcamping‚Äù, ‚Äúscrub‚Äù, and ‚Äúgoat‚Äù all have very specific meanings in this domain that differ from their use in everyday language.</p>
</div>
</div>
</div>
</section>
<section id="step-three" class="level3">
<h3 class="anchored" data-anchor-id="step-three">Train our model using our labelled examples (Step 3)</h3>
<p>The <a href="https://huggingface.co/docs/setfit/index">SetFit documentation</a> provides a really nice overview of SetFit‚Äôs foundational concepts, why this approach is suitable, and details the implementation process.</p>
<p>Before we begin training our SetFit model with our data, it‚Äôs necessary to clean and wrangle the fine-tuning datasets. Specifically, we need to mask any mentions of brands or products to prevent bias. For instance, if a certain brand frequently appears in the training data within peak contexts, the model could erroneously link peak moments to that brand rather than learning the peak-language expressed in the text.</p>
<blockquote class="blockquote">
<p>This precaution should extend to all aspects of our training data that might introduce biases. For example, as we now have examples from various projects, an overrepresentation of data from ‚Äògaming projects‚Äô in our ‚Äòpeak‚Äô posts within our training set (as opposed to the ‚Äòpit‚Äô posts) could skew the model into associating gaming-related language more with peaks than pits.</p>
</blockquote>
<p>At this step, we can split out our data into training, testing, and validation datasets. A good rule of thumb is to split the data 70% to training data, 15% to testing data, and 15% to validation data. By default, <a href="https://huggingface.co/docs/setfit/v1.0.3/en/conceptual_guides/sampling_strategies">SetFit oversamples</a> the minimum class within the training data, so we <em>shouldn‚Äôt</em> have to worry too much about imbalanced datasets- though be aware if we have extreme imbalanced we will end up sampling the same contrastive pairs (normally positive pairs) mutiple times. Indeed, our (Jamie and Aoife) experimentation has shown that class imbalance doesn‚Äôt seem to have a significant effect to the training/output of the SetFit model for peaks and pits.</p>
<p>We are now at the stage where we can actually fine-tune the model. There are many different parameters we can change when fine-tuning the model, such as the specific embedding model used, the number of epochs to train for, the number of contrastive pairs of sentences to train on etc. For more details, please refer to the <a href="https://jamiehshare.github.io/peaks-pits-bookdown/step-four.html">Peaks and Pits Playbook</a></p>
<p>We can access model performance on the testing dataset by looking at accuracy, precision, recall, and F1 scores. For peaks and pits, the most important metric is actually <strong>recall</strong> because in <a href="#gpt35-inference">step 6</a> we reclassify posts using GPT, so we want to make sure we are able to provide <em>as many true peak/pit moments as possible</em> to this step, even if it means we also provide a few false positives.</p>
<section id="visualise-model-separation" class="level6">
<h6 class="anchored" data-anchor-id="visualise-model-separation">Visualise model separation</h6>
<p>A bonus that can be done to check how well our model is able to separate the different classes in embedding space, is to visualise the 2-D structure of the embeddings and see how they cluster:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/embedding_trained.png" class="img-fluid figure-img"></p>
<figcaption>Trained embedding model</figcaption>
</figure>
</div>
<p>For comparison, this is what it looks like on an untrained model:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./img/embedding_untrained.png" class="img-fluid figure-img"></p>
<figcaption>Untrained embedding model</figcaption>
</figure>
</div>
<p>Finally, now we are happy with our model performance based on the training and validation datasets, we can evaluate the performance of this final model using our testing data. This is data that the model has never seen, and we are hoping that the accuracy and performance is similar to that of the validation data. This is Machine Learning 101 and if a refresher is needed for this there are plenty of resources online looking at the role of training, validation, and testing data.</p>
</section>
</section>
<section id="step-four" class="level3">
<h3 class="anchored" data-anchor-id="step-four">Run inference over project data (Step 4)</h3>
<p>It is finally time to infer whether the project data contain peaks or pits by using our fine-tuned SetFit model to classify the posts.</p>
<p>Before doing this again we need to make sure we do some data cleaning on the project specific data.</p>
<p>Broadly, this needs to match the high-level cleaning we did during fine-tuning stage:</p>
<ul>
<li>Mask brand/product mentions (using RoBERTa-based model [or similar] and <code>Rivendell</code> functions)</li>
<li>Remove hashtags #Ô∏è‚É£</li>
<li>Remove mentions üí¨</li>
<li>Remove URLs üåê</li>
<li>Remove emojis üêô</li>
</ul>
<blockquote class="blockquote">
<p>Note: Currently all peak and pit projects have been done on Twitter or Reddit data, but if a project includes web/forum data quirky special characters, numbered usernames, structured quotes etc should also be removed.</p>
</blockquote>
<p>Now we save this dataframe somewhere appropriate.</p>
<p>Okay now we can <em>finally</em> run inference. This is extremely simple and only requires a couple of lines of code (again see the <a href="https://jamiehshare.github.io/peaks-pits-bookdown/step-five.html">Peaks and Pits Playbook for code implementation</a>)</p>
<p>Now we have a .csv file with the probabilities each post is a peak, pit, or neither. From this we can join to our original dataframe via universal_message_id and select the classification label with the highest probability, providing us with a dataframe with all of the relevant information we need for the next steps (unviversal_message_id, message column, and peak/pit classification etc).</p>
</section>
<section id="step-five" class="level3">
<h3 class="anchored" data-anchor-id="step-five">The metal detector, GPT-3.5 (Step 5)</h3>
<p>During <a href="#step-four">step 4</a> we obtained peak and pit classification using few-shot classification with SetFit. The benefit of this approach (as outlined previously) is its speed and ability to classify with very few labelled samples due to contrastive learning.</p>
<p>However, during our iterations of peak and pit projects, we‚Äôve realised that this step still classifies a fair amount of non-peak and pit posts incorrectly. This can cause noise in the downstream analyses and be very time consuming for us to further trudge through verbatims.</p>
<p>As such, the aim here is to further our confidence in our final list of peaks and pits to be <em>actually</em> peaks and pits. Remember before we explained that for SetFit, we focussed on <strong>recall</strong> being the most important measure in our business case? This is where we assume that GPT-3.5 enables us to remove the false positives due to it‚Äôs incredibly high performance.</p>
<blockquote class="blockquote">
<p>Note: Using GPT-3.5 for inference, even over relatively few posts as in peaks and pits, is expensive both in terms of time and money. Preliminary tests have suggested it is in the order of magnitude of thousands of times slower than SetFit. It is for these reasons why we do not use GPT-x models from the get go, despite it‚Äôs obvious incredible understanding of natural language.</p>
</blockquote>
<p>Whilst prompt-based classification such as those with GPT-3.5 certainly has its drawbacks (dependency on prompt quality, prompt injections in posts, handling and version control of complex prompts, unexpected updates to the model weights rendering prompts ineffective), the benefits include increased flexibility in what we can ask the model to do. As such, in the absence of an accurate, cheap, and quick model to perform span detection, we have found that often posts identified as peaks/pits did indeed use peak/pit language, but the context of the moment was not related to the brand/product at the core of the research project.</p>
<p>For example, take the post that we identified in the project 706, looking for peaks and pits relating to PowerPoint:</p>
<blockquote class="blockquote">
<p>This brings me so much happiness! Being a non-binary graduate student in STEM academia can be challenging at times. Despite using my they/them pronouns during introductions, emails, powerpoint presentations, name tags, etc. my identity is continuously mistaken. Community is key!</p>
</blockquote>
<p>This is clearly a ‚Äòpeak‚Äô, however it is not accurate or valid to attribute this memorable moment to PowerPoint. Indeed, PowerPoint is merely mentioned in the post, but is not a core driver of the Peak which relates to feeling connection and being part of a community. This is as much a PowerPoint Peak as it is a Peak for the use of emails.</p>
<p>Therefore, we can engineer our prompt to include a caveat to say that the specific peak or pit moment must relate directly to the brand/product usage (if relevant).</p>
</section>
<section id="step-six" class="level3">
<h3 class="anchored" data-anchor-id="step-six">Topic modelling to make sense of our data (Step 6)</h3>
<p>Now we have an extremely refined set of posts classified as either peak or pits. The next step is to identify what these moments actually relate to (i.e.&nbsp;identify the topics of these moments through statistical methods).</p>
<p>To do this, we employ topic modelling via <a href="https://maartengr.github.io/BERTopic/index.html">BERTopic</a> to identifying high-level topics that emerge within the peak and pit conversation. This is done separately for each product and peak/pit dataset (i.e.&nbsp;there will be one BERTopic model for product A peaks, another BERTopic model for product A pits, an additional BERTopic model for product B peaks etc).</p>
<p>We implement BERTopic using the R package BertopicR. As there is already <a href="https://aoiferyan-sc.github.io/BertopicR/">good documentation on BertopicR</a> this section will not go into any technical detail in regards to implementation.</p>
</section>
<section id="the-idea" class="level3">
<h3 class="anchored" data-anchor-id="the-idea">The idea</h3>
<p>Most of our experiences are not encoded in memory, rather what we remember about experiences are changes, significant moments, and endings</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ai_landscape_workflow.html" class="pagination-link" aria-label="AI landscape">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI landscape</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>