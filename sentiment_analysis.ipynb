{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "As we’ve briefly touched on throughout the Handbook, a common request in projects is to provide the client with an analysis of sentiment ascribed to the documents we are modelling. We nearly always provide details surrounding the breakdown of 'Positive', 'Negative', and 'Neutral' posts across the entire dataset (whether raw or cleaned). Alternatively, we may have a Topic Model or some text classifications upon which we wish to investigate further by breaking out by sentiment, to highlight the most emotive topics within a specific conversation.\n",
        "\n",
        "## Understanding Sentiment\n",
        "\n",
        "Sentiment is the term used to describe the tone of language or the nature of a document based on the users intent of what is being said. For example, if a user posts something like \"I love X product for Y reason…\", we'd almost definitely expect to see this document ascribed with a 'Positive' sentiment. The waters can become quite murky when dealing with sarcasm, jokes or trending language or jargon that machines struggle to classify/understand fully. These classifications can come already baked into a dataset that we'd export from platforms like Sprinklr or Radarly.\n",
        "\n",
        "::: {.callout-note collapse=\"true\"} \n",
        "*We won't always know the origins of our data in terms of where it's been exported, so it's likely that the column containing sentiment-based information may be named something like 'tone' or similar… *\n",
        ":::\n",
        "\n",
        "## Steps Taken in Sentiment Analysis\n",
        "\n",
        "There are a number of ideal steps one must take to ensure an accurate and meaningful sentiment analysis is being conducted. This section will serve to break those steps down into a more manageable and easy to follow pipeline.\n",
        "\n",
        "- Data Processing: A inevitable step to take is the pre-processing and preparation of our data which will set us up for gathering more meaningful insights downstream, with findings more representative of the true nature of our data.\n",
        "- Sentiment Classification: While we can't be sure of where our data will come from in any project, it’s useful (and sometimes optimal) for us to get our own classifications using pre-trained classifiers that are hosted on open source platforms such as HuggingFace. \n",
        "- Analyse Outcome: Analyse the sentiment of the entire dataset first, make note of any heavy skews in Positivity or Negativity. Compare or contrast this to any topic model or segmented data and the sentiment within those.\n",
        "- Visualise and Report: Finally, create meaningful visualisations to portray findings derived from the analysis that illustrate the overall sentiment distribution. Compile the visuals highlighting the insights and key trends that we have observed.\n",
        "\n",
        "## Data Processing\n",
        "\n",
        "We won't dwell on this step too much, as data cleaning is a vast topic and is covered in greater detail [here](http://localhost:7177/data_cleaning.html) in the Tips and Tricks section. However, it is crucial to ensure high data quality when performing any analysis, especially when analysing sentiment. Unclean data can significantly distort sentiment distributions. For example, spam and promotional content often found on social media tend to skew positively due to their use of overly enthusiastic and optimistic language. In summary of this section, be sure to clean data thoroughly and perform the necessary text processing steps on any documents being classified.\n",
        "\n",
        "## Sentiment Classification\n",
        "\n",
        "As we mentioned earlier, most (if not all) datasets we receive from Sprinklr or Radarly will contain some sentiment or similar information related to a post or document. However, we may wish to calculate our own classifications using out-of-the-box pre-trained models or even a classifier we build ourselves. This section will cover a straightforward process for doing so using a pre-trained model from HuggingFace. Each step will be performed using Python modules, with a simple code layout provided throughout, making it easy to follow.\n",
        "\n",
        "### Import Model\n",
        "\n",
        "First, we'll import the exact model and any modules we may need for the workflow. In this instance we will use the `sentiment-roberta-large-english` model which has been trained on Twitter data and we will make use of the pandas library for any data manipulation steps.\n"
      ],
      "id": "e192a051"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from transformers import pipeline # for importing transformers models from HuggingFace \n",
        "import pandas as pd # a module for data manipulation processes\n",
        "\n",
        "# import model from transformers module\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
      ],
      "id": "389e192d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data\n",
        "To perform any kind of text classification, we need texts, so here we will create some data with a column 'message' to resemble a real-world example.\n"
      ],
      "id": "3ec38332"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# create a dataframe object with one Positive, Negative and Neutral 'message' to classify\n",
        "data = {\n",
        "    \"doc_id\": list(range(1, 6)),\n",
        "    \"message\": [\n",
        "        \"I love using this product, it has changed my life.\",\n",
        "        \"This product sucks so bad, don't waste your money\",\n",
        "        \"Very unhappy with the service, it was a disaster.\",\n",
        "        \"I can't recommend this product enough!\",\n",
        "        \"I haven't used it yet, heard it works though\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ],
      "id": "4b6022b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "::: {.callout-note collapse=\"true\"}\n",
        "*For demonstrative purposes, we’ve used a manually constructed dataframe, but it’s likely the user will need something like this to import their data:*\n",
        "\n",
        "`data = pd.read_csv('input/the/path/to/the/files/directory.csv')`\n",
        ":::\n",
        "\n",
        "### Classify Documents\n",
        "Now we have some data, let's look at how we classify texts and retrieve the desired output. First, we'll ensure the column containing our documents is isolated and in the correct format, as a string type list. We can then provide this object to the model so it can perform sentiment classification.\n"
      ],
      "id": "761073b7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "texts = data['message'].astype(str).tolist() # make sure texts is a list of type string\n",
        "sentiment_output = sentiment_model(texts) # using the imported model, derive sentiment classifications"
      ],
      "id": "6cfb16f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# display the results...\n",
        "sentiment_output"
      ],
      "id": "5af6c38c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our use-case example here, we'd expect some direction\n"
      ],
      "id": "982cba1a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}